```{r}
library(tidyverse)
```

```{r}
plot_lognormal_distribution_with_fit <- function(points) {
  # Load required libraries
  library(fitdistrplus)
  
  # Check if points are numeric
  if (!is.numeric(points)) {
    stop("The input 'points' must be a numeric vector.")
  }
  
  # Fit a log-normal distribution to the data
  fit <- fitdist(points, "lnorm")
  
  # Extract parameters from the fit
  meanlog <- fit$estimate["meanlog"]
  sdlog <- fit$estimate["sdlog"]
  
  # Define the range of x values for the curve (adjust range based on the data)
  x_values <- seq(0.01, max(points) * 1.5, length.out = 50000)  # Ensure x starts from a small value above 0
  density_values <- dlnorm(x_values, meanlog = meanlog, sdlog = sdlog)
  
  # Compute the total area under the curve (numerical integration using the trapezoidal rule)
  area_under_curve <- sum(density_values) * (x_values[2] - x_values[1])  # Approximate the integral
  
  # Normalize the density values so that the area under the curve sums to 1
  normalized_density_values <- density_values / area_under_curve  # Normalize
  
  # Create a data frame for the normalized curve
  data_curve <- data.frame(x = x_values, y = normalized_density_values)
  
  # Create a data frame for the points with the log-normal density
  points_data <- data.frame(
    x = points,
    y = dlnorm(points, meanlog = meanlog, sdlog = sdlog) 
  )
  
  # Calculate goodness-of-fit metrics
  log_likelihood <- fit$loglik
  aic <- fit$aic
  ks_test <- ks.test(points, "plnorm", meanlog = meanlog, sdlog = sdlog)
  
  # Kernel density for RMSE calculation
  observed_density <- density(points, n = 100)$y
  fitted_density <- dlnorm(density(points, n = 100)$x, meanlog = meanlog, sdlog = sdlog)
  rmse <- sqrt(mean((observed_density - fitted_density)^2))
  
    # Value-based RMSE: compare raw CVs to simulated ones from the fitted distribution
  set.seed(123)  # For reproducibility
  simulated_values <- rlnorm(length(points), meanlog = meanlog, sdlog = sdlog)
  rmse_values <- sqrt(mean((points - simulated_values)^2))

  
  # Print goodness-of-fit metrics
  cat("Goodness-of-Fit Metrics:\n")
  cat("-----------------------------------\n")
  cat("Log-Likelihood:", round(log_likelihood, 2), "\n")
  cat("AIC:", round(aic, 2), "\n")
  cat("KS Test Statistic:", round(ks_test$statistic, 3), "(p-value:", round(ks_test$p.value, 3), ")\n")
    cat("Density RMSE (shape-based):", round(rmse, 4), "\n")
  cat("Value RMSE (CV units):", round(rmse_values, 4), "\n")

  cat("-----------------------------------\n")
  
  # Print the equation of the log-normal distribution
  cat("Equation of the log-normal distribution:\n")
  cat(paste0("f(x) = 1 / (x * ", round(sdlog, 3), " * sqrt(2 * pi)) * exp(-((log(x) - ", round(meanlog, 3), ")^2) / (2 * ", round(sdlog, 3), "^2))\n"))
  
  # Create the plot
  ggplot(data_curve, aes(x = x, y = y)) +
    geom_line(color = "blue", size = 1) +  # Plot the fitted log-normal curve
    geom_point(data = points_data, aes(x = x, y = y), color = "red", size = 2) +  # Overlay points
    labs(
      title = "Plant CV Log-Normal Distribution Fit",
      subtitle = paste("Meanlog =", round(meanlog, 3), ", Sdlog =", round(sdlog, 3)),
      x = "Plant CV Values",
      y = "Normalized Probability Density"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
      plot.subtitle = element_text(hjust = 0.5, size = 10, face = "italic"),
      axis.title = element_text(face = "bold", size = 12)
    ) +
    xlim(0, NA)  # Ensure x-axis starts at 0 and extends automatically
  
  values = data.frame(meanlog_value = round(meanlog, 4), sdlog_value = round(sdlog, 4))
  
  return(values)
}
```

```{r}
points = Plant_CV_numeric
# Check if points are numeric
  if (!is.numeric(points)) {
    stop("The input 'points' must be a numeric vector.")
  }
  
  # Fit a log-normal distribution to the data
  fit <- fitdist(points, "lnorm")
  
  # Extract parameters from the fit
  meanlog <- fit$estimate["meanlog"]
  sdlog <- fit$estimate["sdlog"]
  
  # Define the range of x values for the curve (adjust range based on the data)
  x_values <- seq(0.01, max(points) * 1.5, length.out = 5000)  # Ensure x starts from a small value above 0
  density_values <- dlnorm(x_values, meanlog = meanlog, sdlog = sdlog)
  
  # Compute the total area under the curve (numerical integration using the trapezoidal rule)
  area_under_curve <- sum(density_values) * (x_values[2] - x_values[1])  # Approximate the integral
  
  # Normalize the density values so that the area under the curve sums to 1
  normalized_density_values <- density_values / area_under_curve  # Normalize
  
  # Create a data frame for the normalized curve
  data_curve <- data.frame(x = x_values, y = normalized_density_values)
  
  # Create a data frame for the points with the log-normal density
  points_data <- data.frame(
    x = points,
    y = dlnorm(points, meanlog = meanlog, sdlog = sdlog) 
  )
  
  # Calculate goodness-of-fit metrics
  log_likelihood <- fit$loglik
  aic <- fit$aic
  ks_test <- ks.test(points, "plnorm", meanlog = meanlog, sdlog = sdlog)
  
  # Kernel density for RMSE calculation
  observed_density <- density(points, n = 100)$y
  fitted_density <- dlnorm(density(points, n = 100)$x, meanlog = meanlog, sdlog = sdlog)
  rmse <- sqrt(mean((observed_density - fitted_density)^2))
  
  # Print goodness-of-fit metrics
  cat("Goodness-of-Fit Metrics:\n")
  cat("-----------------------------------\n")
  cat("Log-Likelihood:", round(log_likelihood, 2), "\n")
  cat("AIC:", round(aic, 2), "\n")
  cat("KS Test Statistic:", round(ks_test$statistic, 3), "(p-value:", round(ks_test$p.value, 3), ")\n")
  cat("RMSE:", round(rmse, 4), "\n")
  cat("-----------------------------------\n")
  
  # Print the equation of the log-normal distribution
  cat("Equation of the log-normal distribution:\n")
  cat(paste0("f(x) = 1 / (x * ", round(sdlog, 3), " * sqrt(2 * pi)) * exp(-((log(x) - ", round(meanlog, 3), ")^2) / (2 * ", round(sdlog, 3), "^2))\n"))
  
  # Create the plot
  ggplot(data_curve, aes(x = x, y = y)) +
    geom_line(color = "blue", size = 1) +  # Plot the fitted log-normal curve
    geom_point(data = points_data, aes(x = x, y = y), color = "red", size = 0.1) +  # Overlay points
    labs(
      title = "Log-Normal Distribution Fit with Points",
      subtitle = paste("Meanlog =", round(meanlog, 3), ", Sdlog =", round(sdlog, 3)),
      x = "Tobacco CV",
      y = "Normalized Probability Density"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
      plot.subtitle = element_text(hjust = 0.5, size = 10, face = "italic"),
      axis.title = element_text(face = "bold", size = 12)
    ) +
    xlim(0, NA)  # Ensure x-axis starts at 0 and extends automatically
```

```{r}
plot_lognormal_distribution_with_probabilities <- function(points) {
  # Load required libraries
  library(ggplot2)
  library(fitdistrplus)
  
  # Check if points are numeric
  if (!is.numeric(points)) {
    stop("The input 'points' must be a numeric vector.")
  }
  
  # Fit a log-normal distribution to the data
  fit <- fitdist(points, "lnorm")
  
  # Extract parameters from the fit
  meanlog <- fit$estimate["meanlog"]
  sdlog <- fit$estimate["sdlog"]
  
  # Define the range of x values for the curve (adjust range based on the data)
  x_values <- seq(0.01, max(points) * 1.5, length.out = 500)  # Ensure x starts from a small value above 0
  
  # Compute the cumulative distribution function (CDF) for each x value
  cdf_values <- plnorm(x_values, meanlog = meanlog, sdlog = sdlog)
  
  # Normalize the CDF values to probabilities (from 0 to 1)
  # This is already scaled by `plnorm`, so no further normalization is needed here.
  
  # Create a data frame for the normalized curve
  data_curve <- data.frame(x = x_values, y = cdf_values)
  
  # Create a data frame for the points with the log-normal density
  points_data <- data.frame(
    x = points,
    y = plnorm(points, meanlog = meanlog, sdlog = sdlog)
  )
  
  # Calculate goodness-of-fit metrics
  log_likelihood <- fit$loglik
  aic <- fit$aic
  ks_test <- ks.test(points, "plnorm", meanlog = meanlog, sdlog = sdlog)
  
  # Kernel density for RMSE calculation
  observed_density <- density(points, n = 100)$y
  fitted_density <- dlnorm(density(points, n = 100)$x, meanlog = meanlog, sdlog = sdlog)
  rmse <- sqrt(mean((observed_density - fitted_density)^2))
  
  # Print goodness-of-fit metrics
  cat("Goodness-of-Fit Metrics:\n")
  cat("-----------------------------------\n")
  cat("Log-Likelihood:", round(log_likelihood, 2), "\n")
  cat("AIC:", round(aic, 2), "\n")
  cat("KS Test Statistic:", round(ks_test$statistic, 3), "(p-value:", round(ks_test$p.value, 3), ")\n")
  cat("RMSE:", round(rmse, 4), "\n")
  cat("-----------------------------------\n")
  
  # Print the equation of the log-normal distribution
  cat("Equation of the log-normal distribution:\n")
  cat(paste0("f(x) = 1 / (x * ", round(sdlog, 3), " * sqrt(2 * pi)) * exp(-((log(x) - ", round(meanlog, 3), ")^2) / (2 * ", round(sdlog, 3), "^2))\n"))
  
  # Create the plot
  ggplot(data_curve, aes(x = x, y = y)) +
    geom_line(color = "blue", size = 1) +  # Plot the fitted log-normal curve
    geom_point(data = points_data, aes(x = x, y = y), color = "red", size = 0.1) +  # Overlay points
    labs(
      title = "Plant CV Log-Normal Distribution Fit with Probabilities",
      subtitle = paste("Meanlog =", round(meanlog, 3), ", Sdlog =", round(sdlog, 3)),
      x = "Plant CV Value",
      y = "Cumulative Probability"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
      plot.subtitle = element_text(hjust = 0.5, size = 10, face = "italic"),
      axis.title = element_text(face = "bold", size = 12)
    ) +
    xlim(0, NA)  # Ensure x-axis starts at 0 and extends automatically
}

```

```{r}
compare_2 = function(effect_size){
  
low_value = 100000
effect_size_to_add = (100000 * effect_size) - 100000
true_values <- data.frame(
  construct = c(1,2),
  value = c(low_value,
            low_value + effect_size_to_add))

percent_valid_tests = data.frame(plant_number = NULL, percent_valid = NULL)
number_tests = 1000
conglomerate_tests = data.frame(plant_number = NULL, GFP = NULL, construct = NULL,
                                rep = NULL, total_plants = NULL)
conglomerate_tests_collect = FALSE

experimental_summary = data.frame(ranked_properly = NULL, t_test_percent = NULL, plant_number = NULL, rep = NULL)

#defines total number of plants that will be tested
for(plant_number in 1:12){
  number_plants_to_generate = plant_number
  number_successful_comparisons = 0
  
  print(number_plants_to_generate)
  
  #number simulations
  for(iterations in 1:number_tests){
    GFP_distribution = data.frame(plant_number = NULL, GFP = NULL, construct = NULL)
    weekly_CV = generate_weekly_CV_average()
    
    #defined number of constructs
    for(construct in 1:length(true_values$construct)){
      
      #defines number of plants for this iteration
      for(plants in 1:number_plants_to_generate){
        plant_CV = generate_plant_CV(weekly_CV) #generate plant
        plant_number = as.factor(plants)
        
        GFP_output = generate_8_disks(true_values$value[construct], plant_CV, plant_number)
        GFP_output = GFP_output %>% mutate(construct = true_values$construct[construct])
        
        GFP_distribution = rbind(GFP_distribution, GFP_output)
      }
      
      if(conglomerate_tests_collect == TRUE){
        experiment_data = GFP_distribution %>% 
          mutate(rep = as.factor(iterations), total_plants = as.factor(number_plants_to_generate))
        conglomerate_tests = rbind(conglomerate_tests, experiment_data)
      }
    }
    
    #determine if experiment can successfully differentiate all samples
    iteration_results = calculate_ranking_significance(GFP_distribution)
    iteration_results = iteration_results %>% mutate(total_plant_number = number_plants_to_generate,
                                                     rep = as.factor(iterations))
    
    
    if(iterations %% 100 == 0){
      print(paste(c(iterations, "iterations of plant number ", number_plants_to_generate, " completed")))
    }
    
    experimental_summary = rbind(experimental_summary, iteration_results)
  }
  
  
}
experimental_summary = experimental_summary %>% mutate(effect_size = effect_size)
return(experimental_summary)
}
```

```{r}
compare_2_EHA105 = function(effect_size){
  
low_value = 100000
effect_size_to_add = (100000 * effect_size) - 100000
true_values <- data.frame(
  construct = c(1,2),
  value = c(low_value,
            low_value + effect_size_to_add))

percent_valid_tests = data.frame(plant_number = NULL, percent_valid = NULL)
number_tests = 1000
conglomerate_tests = data.frame(plant_number = NULL, GFP = NULL, construct = NULL,
                                rep = NULL, total_plants = NULL)
conglomerate_tests_collect = FALSE

experimental_summary = data.frame(ranked_properly = NULL, t_test_percent = NULL, plant_number = NULL, rep = NULL)

#defines total number of plants that will be tested
for(plant_number in 1:20){
  number_plants_to_generate = plant_number
  number_successful_comparisons = 0
  
  print(number_plants_to_generate)
  
  #number simulations
  for(iterations in 1:number_tests){
    GFP_distribution = data.frame(plant_number = NULL, GFP = NULL, construct = NULL)
    weekly_CV = generate_weekly_CV_average_EHA105()
    
    #defined number of constructs
    for(construct in 1:length(true_values$construct)){
      
      #defines number of plants for this iteration
      for(plants in 1:number_plants_to_generate){
        plant_CV = generate_plant_CV(weekly_CV) #generate plant
        plant_number = as.factor(plants)
        
        GFP_output = generate_8_disks(true_values$value[construct], plant_CV, plant_number)
        GFP_output = GFP_output %>% mutate(construct = true_values$construct[construct])
        
        GFP_distribution = rbind(GFP_distribution, GFP_output)
      }
      
      if(conglomerate_tests_collect == TRUE){
        experiment_data = GFP_distribution %>% 
          mutate(rep = as.factor(iterations), total_plants = as.factor(number_plants_to_generate))
        conglomerate_tests = rbind(conglomerate_tests, experiment_data)
      }
    }
    
    #determine if experiment can successfully differentiate all samples
    iteration_results = calculate_ranking_significance(GFP_distribution)
    iteration_results = iteration_results %>% mutate(total_plant_number = number_plants_to_generate,
                                                     rep = as.factor(iterations))
    
    
    if(iterations %% 100 == 0){
      print(paste(c(iterations, "iterations of plant number ", number_plants_to_generate, " completed")))
    }
    
    experimental_summary = rbind(experimental_summary, iteration_results)
  }
  
  
}
experimental_summary = experimental_summary %>% mutate(effect_size = effect_size)
return(experimental_summary)
}
```

```{r}
##Comparing just 2 constructs
effect_size_simulation_2_samples = compare_2(1.05)
effect_size_simulation_2_samples = rbind(effect_size_simulation_2_samples, compare_2(1.1))
effect_size_simulation_2_samples = rbind(effect_size_simulation_2_samples, compare_2(1.2))
effect_size_simulation_2_samples = rbind(effect_size_simulation_2_samples, compare_2(1.3))
effect_size_simulation_2_samples = rbind(effect_size_simulation_2_samples, compare_2(1.4))
effect_size_simulation_2_samples = rbind(effect_size_simulation_2_samples, compare_2(1.5))
effect_size_simulation_2_samples= rbind(effect_size_simulation_2_samples, compare_2(1.6))
effect_size_simulation_2_samples = rbind(effect_size_simulation_2_samples, compare_2(2))

effect_size_simulation_2_samples$t_tests_correct = effect_size_simulation_2_samples$t_tests_correct - 9

effect_size_simulation_2_samples_summarized = effect_size_simulation_2_samples %>% 
  mutate(plant_factor = as.factor(total_plant_number), effect_size_factor = as.factor(effect_size)) %>%
  group_by(effect_size_factor, total_plant_number) %>% summarize(percent_correct = 100 * (sum(t_tests_correct) / 1000))

effect_size_simulation_2_samples_summarized %>%
  ggplot(aes(x = total_plant_number, y = percent_correct)) + geom_point() + facet_wrap(~effect_size_factor)

effect_size_simulation_2_samples_summarized %>%
  ggplot(aes(x = total_plant_number, y = percent_correct, color = effect_size_factor)) + geom_point() + geom_smooth() +
  theme_light() +
  labs(title = "Plant number vs test accuracy") +
  theme(
    axis.text.x = element_text(face = "bold", color = "black", size = 10),
    axis.text.y = element_text(face = "bold", color = "black", size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2)
  ) +
  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, by = 10)) +
  scale_x_continuous(limits = c(1, 12), breaks = seq(1, 12, by = 1)) +
  xlab("Plant number") +  
  ylab("Percent accurate tests")

two_sample_comp = effect_size_simulation_2_samples_summarized %>% filter(percent_correct > 95) %>% group_by(effect_size_factor) %>%
  summarize(minimum = min(total_plant_number)) %>% 
  ggplot(aes(x = effect_size_factor, y = minimum)) + geom_col() +
  theme_light() +
  labs(title = "Effect size vs required plant number for >95% accurate comparison probability") +
  theme(
    axis.text.x = element_text(face = "bold", color = "black", size = 10),
    axis.text.y = element_text(face = "bold", color = "black", size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2)
  ) +
  scale_y_continuous(limits = c(0, 12), breaks = seq(0, 12, by = 1)) +  # Set y-axis limits from 0 to 10
  xlab("Effect size (fold difference in GFP expression)") +  
  ylab("Plants required")


#############
#Compare using EHA105

EHA105_1.2 = compare_2_EHA105(1.2)
EHA105_1.3 = compare_2_EHA105(1.3)
EHA105_1.4 = compare_2_EHA105(1.4)
EHA105_1.5 = compare_2_EHA105(1.5)
EHA105_1.6 = compare_2_EHA105(1.6)
EHA105_2 = compare_2_EHA105(2)

EHA105_modeling = rbind(EHA105_1.2, EHA105_1.3)
EHA105_modeling = rbind(EHA105_modeling, EHA105_1.4)
EHA105_modeling = rbind(EHA105_modeling, EHA105_1.5)
EHA105_modeling = rbind(EHA105_modeling, EHA105_1.6)
EHA105_modeling = rbind(EHA105_modeling, EHA105_2)

EHA105_modeling$t_tests_correct = EHA105_modeling$t_tests_correct - 9

EHA105_plants_needed = EHA105_modeling %>% 
  mutate(total_plant_number_factor = as.factor(total_plant_number), effect_size_factor = as.factor(effect_size)) %>%
  group_by(effect_size_factor, total_plant_number) %>% summarize(percent_accurate = 100 * (sum(t_tests_correct)/1000)) %>%
  filter(percent_accurate > 94) %>% group_by(effect_size_factor) %>%
  summarize(minimum = min(total_plant_number)) %>% mutate(Strain = "EHA105")

GV3101_plants_needed = effect_size_simulation_2_samples %>% 
  mutate(total_plant_number_factor = as.factor(total_plant_number), effect_size_factor = as.factor(effect_size)) %>%
  group_by(effect_size_factor, total_plant_number) %>% summarize(percent_accurate = 100 * (sum(t_tests_correct)/1000)) %>%
  filter(percent_accurate > 95) %>% group_by(effect_size_factor) %>%
  summarize(minimum = min(total_plant_number)) %>% mutate(Strain = "GV3101")

EHA105_GV3101_min_plants = rbind(EHA105_plants_needed, GV3101_plants_needed)

EHA105_modeling_summarized = EHA105_GV3101_min_plants %>%
  ggplot(aes(x = effect_size_factor, y = minimum, fill = Strain)) + geom_col(position = position_dodge()) +
  theme_light() +
  labs(title = "Effect size vs required plant number for >95% accurate comparison probability") +
  theme(
    axis.text.x = element_text(face = "bold", color = "black", size = 10),
    axis.text.y = element_text(face = "bold", color = "black", size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold", size = 12),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2)
  ) +
  scale_y_continuous(limits = c(0, 20), breaks = seq(0, 20, by = 1)) +  # Set y-axis limits from 0 to 10
  xlab("Effect size (fold difference in GFP expression)") +  
  ylab("Plants required")

EHA105_GV3101_min_plants %>% ggplot(aes(x = as.numeric(effect_size_factor), y = minimum, color = Strain)) + geom_point() +
  geom_smooth()
######
effect_size_simulation_reloaded = effect_size_simulation_reloaded %>% 
  mutate(total_plant_number_factor = as.factor(effect_size_simulation_reloaded$total_plant_number),
                                    effect_size_factor = as.factor(effect_size_simulation_reloaded$effect_size))

effect_size_simulation_reloaded %>% group_by(total_plant_number_factor, effect_size_factor) %>%
  summarize(effect_size_factor, total_plant_number,
            proper_ranking_percent = 100 * (mean(proper_ranking))) %>% unique() %>%
  ggplot(aes(x =  total_plant_number, y = proper_ranking_percent, color = effect_size_factor)) + 
  geom_smooth() + 
  geom_point() 

effect_size_simulation_reloaded %>% group_by(total_plant_number_factor, effect_size_factor) %>%
  summarize(effect_size_factor, total_plant_number,
            t_test_percent = 10 * mean(t_tests_correct)) %>% unique() %>%
  ggplot(aes(x =  total_plant_number, y = t_test_percent, color = effect_size_factor)) + 
  geom_smooth(se = FALSE) + 
  geom_point() +
  theme_light() +
  labs(title = "Percent accurate t-tests vs. Plant Number") +
  theme(
    axis.text.x = element_text(face = "bold", color = "black", size = 10),
    axis.text.y = element_text(face = "bold", color = "black", size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2)
  ) +
  scale_x_continuous(limits = c(1, 12), breaks = seq(1, 12, by = 1)) +  # Set y-axis limits from 0 to 10
  xlab("Plant Number") +  
  ylab("Number of Accurate Tests")


combined %>%
  ggplot(aes(x = total_plant_number_factor, y = t_tests_correct)) + 
  geom_jitter(width = 0.2, height = 0.2, size = 0.01) +  # Jitter for better visibility
  theme_light() +
  labs(title = "Number of Accurate t-tests vs. Plant Number") +
  theme(
    axis.text.x = element_text(face = "bold", color = "black", size = 10),
    axis.text.y = element_text(face = "bold", color = "black", size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2)
  ) +
  scale_y_continuous(limits = c(0, 10.5), breaks = seq(0, 10, by = 1)) +  # Set y-axis limits from 0 to 10
  xlab("Plant Number") +  
  ylab("Number of Accurate Tests") + facet_wrap(~effect_size_factor)
```

```{r}
#This function will look at the average of each construct and rank it relative to the other constructs.
#It will then determine if the constructs are ranked accurately.
#If they are, it will then determine if the distributions are statistically significantly different
#If all rankings are, it will return a 1; if not, return a 0

calculate_ranking_significance = function(GFP_distribution){
  distribution = GFP_distribution %>% mutate(ranking = as.factor(construct))
  
  averages = distribution %>%
    group_by(ranking) %>%
    summarize(average = mean(GFP)) %>%
    arrange(average) %>%
    mutate(calculated_ranking = as.factor(row_number()))
  
  true_rank_values = as.integer(averages$ranking)
  calculated_rank_values = as.integer(averages$calculated_ranking)
  
  correctly_ranked = ifelse(identical(true_rank_values, calculated_rank_values) == TRUE, 1, 0)
  
  p_values = pairwise.t.test(distribution$GFP, distribution$construct, p.adjust.method = "BH")
  
  number_correct = 10 - sum(p_values$p.value > 0.05, na.rm = TRUE)

  #anova_result = aov(GFP ~ ranking, data = distribution)
  #tukey_test = TukeyHSD(anova_result)
  
  #looks at the largest p-valsue of all comparisons
  #if(max(tukey_test$ranking[,4]) > 0.05){
   # return(0)
  #}
  summary = data.frame(proper_ranking = correctly_ranked, t_tests_correct = number_correct)
  
  return(summary)
}

```

#generates 8 GFP values given the GFP global mean for the construct and the plant CV
```{r}
generate_8_disks <- function(GFP_average, Plant_CV, Plant_ID) {
  # Calculate standard deviation
  sd_value <- GFP_average * Plant_CV
  
  # Initialize disk_outputs vector
  disk_outputs <- rep(0, 8)
  
  # Generate values ensuring all are positive
  while(any(disk_outputs <= 0)) {
    disk_outputs <- round(rnorm(8, mean = GFP_average, sd = sd_value))
  }
  
  # Create a data frame
  data_frame <- data.frame(plant_number = Plant_ID, GFP = disk_outputs)
  
  return(data_frame)
}
```

#generates the plant CV distribution for the week
```{r}
generate_weekly_CV_average = function(){
  weekly_CV_meanlog = -1.447  #meanlog of weekly CVs
  weekly_CV_sdlog = 0.3    # sdlog of weekly CVs

  y = runif(1, min = 0, max = 1)

  # Compute the corresponding x value
  weeks_CV <- qlnorm(y, meanlog = weekly_CV_meanlog, sdlog = weekly_CV_sdlog)
  
  ####################################################################
  #adds stochastic standard deviation of CV based on our data
  CV_sd_meanlog = -2.3248 #meanlog of weekly sd's of CV values
  CV_sd_sdlog = 0.3897 #sd log of weekly sd's of CV values

  magnitiude_sd_of_CV <- runif(1, min = 0, max = 1)  

  # Compute the corresponding x value
  sd_of_CV <- qlnorm(magnitiude_sd_of_CV, meanlog = CV_sd_meanlog, sdlog = CV_sd_sdlog)
  
  
  # Compute sdlog
  sdlog <- sqrt(log(1 + (sd_of_CV^2 / weeks_CV^2)))
  
  generated_weekly_CV = data.frame(log_CV = log(weeks_CV), log_sd = sdlog)
  
  return(generated_weekly_CV)
}
```

#generate weekly CV average for EHA105
```{r}
generate_weekly_CV_average_EHA105 = function(){
  weekly_CV_meanlog = -0.903  #meanlog of weekly CVs
  weekly_CV_sdlog = 0.46    # sdlog of weekly CVs

  y = runif(1, min = 0, max = 1)

  # Compute the corresponding x value
  weeks_CV <- qlnorm(y, meanlog = weekly_CV_meanlog, sdlog = weekly_CV_sdlog)
  
  ####################################################################
  #adds stochastic standard deviation of CV based on our data 
  #DO NOT HAVE FOR EHA105
  CV_sd_meanlog = -2.3248 #meanlog of weekly sd's of CV values
  CV_sd_sdlog = 0.3897 #sd log of weekly sd's of CV values

  magnitiude_sd_of_CV <- runif(1, min = 0, max = 1)  

  # Compute the corresponding x value
  sd_of_CV <- qlnorm(magnitiude_sd_of_CV, meanlog = CV_sd_meanlog, sdlog = CV_sd_sdlog)
  
  
  # Compute sdlog
  sdlog <- sqrt(log(1 + (sd_of_CV^2 / weeks_CV^2)))
  
  generated_weekly_CV = data.frame(log_CV = log(weeks_CV), log_sd = sdlog)
  
  
  
  return(generated_weekly_CV)
}
```

#generate plant CV
```{r}
#generates random plant CV given data on the weeks plant quality
#takes in weeks CV average and sd

generate_plant_CV = function(weekly_CV_average){
  #bounds generated CVs to biologically relevant values of 0.03-2
  CV = 0
  
  total_iterations = 0
  while(CV < 0.03 | CV > 2){
  #sdlog = 0.420 #derived from bulk data set. 
  #Commented out as this function now uses a randomized sdlog generation based on our data
  
  meanlog = weekly_CV_average$log_CV
  sdlog = weekly_CV_average$log_sd
  

  #calculate the CV value of this plant 
  #uses the weekly CV mean and the randomized CV sd spread for the week
  
  
  # random number between 0 and 1 defining the percentile to use
  percentile <- runif(1, min = 0, max = 1)  

  # Compute the corresponding x value
  CV <- qlnorm(percentile, meanlog = meanlog, sdlog = sdlog)
  total_iterations = total_iterations + 1
  
  if(total_iterations > 20){
    CV = 0.5
  }
  }
  
  return(CV)
}
```

```{r}
plant_overview = data.frame(CV = NULL, Week = NULL)
for(week in 1:1000){
  weekly_CV = generate_weekly_CV_average()
  for(plant in 1:20){
    random_plant = generate_plant_CV(weekly_CV)
    random_plant = data.frame(CV = random_plant, Week = week)
    plant_overview = rbind(plant_overview, random_plant)
  }
  if(week %% 100 == 0){
    print(week)
  }
}

plant_overview$Week_Factor = as.factor(plant_overview$Week)
subset35 = plant_overview %>% filter(Week <= 35)

subset35 %>% ggplot(aes(x = reorder(Week_Factor,CV, median), y = CV)) + geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.01, height = 0, size = 0.05)

subset35 %>% ggplot(aes(x = "", y = CV)) + geom_violin(width = 0.4) + geom_jitter(width = 0.05, height = 0, size = 0.2) +
  theme_light() +
  labs(title = "Simulated plant CVs over 35 weeks") +
  theme(
    axis.text.x = element_text(face = "bold", color = "black", size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2),
  ) +
  ylab("Plant CVs")

plant_overview %>% ggplot(aes(x = reorder(Week_Factor,CV, median), y = CV)) + geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.01, height = 0, size = 0.05)

plant_overview %>% ggplot(aes(x = "", y = CV)) + geom_violin(width = 0.4) + 
  geom_jitter(width = 0.05, height = 0, size = 0.2) +
  theme_light() +
  labs(title = "Simulated plant CVs over 1000 weeks") +
  theme(
    axis.text.x = element_text(face = "bold", color = "black", size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2),
  ) +
  ylab("Plant CVs")

#compiled_data_PlantCV = read.csv(from main data file)
compiled_data_PlantCV %>% ggplot(aes(x = reorder(ORI,Plant_CV, median), y = Plant_CV)) + geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.01, height = 0, size = 0.05)

compiled_data_PlantCV %>% filter(Strain == "GV3101") %>%
  ggplot(aes(x = "", y = Plant_CV)) + geom_violin(width = 0.4) + 
  geom_boxplot(width = 0.1, outlier.shape = NA)+
theme_light() +
  labs(title = "Real Plant CV distribution over 35 weeks") +
  theme(
    axis.text.x = element_text(face = "bold", color = "black", size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2),
  ) +
  ylab("Plant CVs")


combined_simulated_real = compiled_data_PlantCV %>% filter(Strain == "GV3101") %>% reframe(ORI, Plant_CV) %>%
  mutate(Simulated = "32 weeks, real data") %>%
  rename(Week = ORI, CV = Plant_CV)

simulated = plant_overview %>% reframe(CV, Week) %>% mutate(Simulated = "1000 weeks, simulation")

combined_simulated_real = rbind(combined_simulated_real, simulated)

first_32 = plant_overview %>% filter(Week >= 1 & Week <= 32) %>% 
  reframe(CV, Week) %>% mutate(Simulated = "32 weeks, simulation 1")
second_32 = plant_overview %>% filter(Week >= 33 & Week <= 64) %>%
reframe(CV, Week) %>% mutate(Simulated = "32 weeks, simulation 2")
third_32 = plant_overview %>% filter(Week >= 65 & Week <= 96) %>%
  reframe(CV, Week) %>% mutate(Simulated = "32 weeks, simulation")

combined_simulated_real = rbind(combined_simulated_real, second_32)

combined_simulated_real$Simulated = factor(combined_simulated_real$Simulated, levels = c(
  "32 weeks, real data", "32 weeks, simulation 1", "32 weeks, simulation 2", "32 weeks, simulation", "1000 weeks, simulation"
))

individual_plants = combined_simulated_real %>% 
  ggplot(aes(x = Simulated, y = CV)) + geom_violin(width = 0.4) + 
  geom_boxplot(width = 0.1, outlier.shape = NA) +
  theme_light() +
  labs(title = "Real vs simulated individual plant CVs") +
  theme(
    axis.text.x = element_text(face = "bold", color = "black", size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2),
  ) +
  ylab("Plant CVs") +
  xlab("")

#model validation
ggplot() +
  geom_density(data = real_df, aes(x = PlantCV), color = "black", size = 1.2) +
  geom_density(data = sim_df, aes(x = PlantCV), color = "red", linetype = "dashed", size = 1.2) +
  theme_minimal() +
  labs(title = "Plant CV Distribution: Real vs Simulated", x = "Plant CV", y = "Density")

# ECDF
ggplot() +
  stat_ecdf(data = real_df, aes(x = PlantCV), color = "black") +
  stat_ecdf(data = sim_df, aes(x = PlantCV), color = "red", linetype = "dashed") +
  theme_minimal() +
  labs(title = "ECDF of Plant CVs: Real vs Simulated", x = "Plant CV", y = "ECDF")

#Weekly variance modeling
combined_simulated_real = combined_simulated_real %>% 
  filter(Simulated %in% c("32 weeks, real data", "1000 weeks, simulation"))

# Density plot
ggplot(combined_simulated_real, aes(x = CV, color = Simulated)) +
  geom_density(size = 1.2) +
  theme_minimal() +
  labs(title = "Distribution of PlantCV: Real vs Simulated", x = "PlantCV", y = "Density")

# ECDF plot
combined_simulated_real %>% 
  ggplot(aes(x = CV, color = Simulated)) +
  stat_ecdf(size = 1.2) +
  theme_minimal() +
  labs(title = "ECDF of PlantCV: Real vs Simulated", x = "PlantCV", y = "ECDF")

combined_simulated_real %>% group_by(Simulated) %>%
  summarize(median = median(CV), mean = mean(CV), sd = sd(CV))

qqplot(
  combined_simulated_real$CV[combined_simulated_real$Simulated == "32 weeks, real data"],
  combined_simulated_real$CV[combined_simulated_real$Simulated == "1000 weeks, simulation"],
  main = "QQ Plot: Real vs Simulated PlantCV",
  xlab = "Real PlantCV",
  ylab = "Simulated PlantCV"
) 
abline(0, 1, col = "blue")

library(transport)
wasserstein1d(
  combined_simulated_real$CV[combined_simulated_real$Simulated == "32 weeks, real data"],
  combined_simulated_real$CV[combined_simulated_real$Simulated == "1000 weeks, simulation"]
)

#####GRAPH OF MODEL EVAL

# Extract values
real_vals <- combined_simulated_real$CV[combined_simulated_real$Simulated == "32 weeks, real data"]
sim_vals  <- combined_simulated_real$CV[combined_simulated_real$Simulated == "1000 weeks, simulation"]

# ECDFs
ecdf_real <- ecdf(real_vals)
ecdf_sim  <- ecdf(sim_vals)

# Common grid
x_vals <- sort(unique(c(real_vals, sim_vals)))
y_real <- ecdf_real(x_vals)
y_sim  <- ecdf_sim(x_vals)

# Wasserstein distance
wasserstein <- sum(abs(y_real - y_sim)) / length(y_real)

# Prepare plot_df for ECDF curves
plot_df <- data.frame(
  CV = x_vals,
  `32 weeks, real data` = y_real,
  `1000 weeks, simulation` = y_sim
) %>%
  pivot_longer(cols = -CV, names_to = "Group", values_to = "ECDF") %>%
  mutate(Group = factor(Group, levels = c("32 weeks, real data", "1000 weeks, simulation"))) %>%
  group_by(CV) %>%
  mutate(
    ymin = min(ECDF),
    ymax = max(ECDF)
  ) %>%
  ungroup()

# Final plot
ggplot(plot_df, aes(x = CV)) +
  geom_step(aes(y = ECDF, color = Group), size = 1.2, show.legend = TRUE) +
  geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = "gray80", alpha = 0.4) +
  scale_color_manual(
    name = "Data Source",
    values = c("32 weeks, real data" = "black", "1000 weeks, simulation" = "red")
  ) +
  labs(
    title = "ECDF of Plant CVs: Real Data vs Simulation",
    subtitle = paste0("Wasserstein Distance = ", round(wasserstein, 3)),
    x = "Plant CV",
    y = "Cumulative Probability"
  ) +
  theme_minimal(base_size = 14)


###############

subsample_weekly_CV = variance_overview %>% filter(Week >= 1 & Week <= 32)

variance_overview = variance_overview  %>%
  mutate(variance = exp(variance_overview$CV_median.log_CV), Week = as.factor(Week), simulated = "1000 weeks, simulated") %>%
  reframe(variance, Week, simulated)

subsample_weekly_CV = subsample_weekly_CV  %>%
  mutate(variance = exp(subsample_weekly_CV$CV_median.log_CV), Week = as.factor(Week), simulated = "32 weeks, simulated") %>%
  reframe(variance, Week, simulated)

weekly_variance = rbind(variance_overview, subsample_weekly_CV)

GV3101_weekly_CV = compiled_data_PlantCV %>% filter(Strain == "GV3101") %>%
  group_by(ORI) %>% summarise(variance = median(Plant_CV)) %>%
  rename(Week = ORI) %>% mutate(simulated = "32 weeks, real data")

weekly_variance = rbind(weekly_variance, GV3101_weekly_CV)


weekly_variance$simulated = factor(weekly_variance$simulated, levels = c("32 weeks, real data", "32 weeks, simulated", "1000 weeks, simulated"))

weekly_CV_Average = weekly_variance %>% filter(simulated != "32 weeks, simulated") %>%
ggplot(aes(x = simulated, y = variance)) + geom_violin(width = 0.4) + 
  geom_boxplot(width = 0.1, outlier.shape = NA) +
  theme_light() +
  labs(title = "Real vs simulated weekly mean CVs") +
  theme(
    axis.text.x = element_text(face = "bold", color = "black", size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2),
  ) +
  ylab("Plant CVs") +
  xlab("")

```
```{r}

weekly_norm_CVs = weekly_norm %>% group_by(Red.Promoter, Date, Plant) %>% 
  summarize(Plant_CV_green = sd(Green)/mean(Green), Plant_CV_normalized = sd(Green.Red) / mean(Green.Red))

condition_summary = weekly_norm_CVs %>% group_by(Red.Promoter) %>% 
  summarize(mean_CV_green = mean(Plant_CV_green), mean_CV_normalize = mean(Plant_CV_normalized))

#PCH4: 0.165
#PCH5: 0.192
#PCL1: 0.198
#PCL2: 0.081
#PCM1: 0.125
#PCM2: 0.186
#GFP alone: 0.170

#PCH4
PCH4 = weekly_norm %>% filter(Red.Promoter == "PCH4") %>% group_by(Plant, Date) %>%
  summarize(Plant_CV = sd(Green.Red)/mean(Green.Red))

plot_lognormal_distribution_with_fit(PCH4$Plant_CV)
plot_lognormal_distribution_with_probabilities(PCH4$Plant_CV)
#meanlog = -1.865
#sdlog = 0.354
PCH4_effect_10 = compare_2_custom(1.2, pops_meanlog = -1.865, pops_sdlog = 0.354)
PCH4_effect_10$t_tests_correct = PCH4_effect_10$t_tests_correct - 9
PCH4_effect_10$total_plant_number = as.factor(PCH4_effect_10$total_plant_number)
PCH4_effect20_summary = PCH4_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100 * (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCH4")

test = 67
#PCH5
PCH5 = weekly_norm %>% filter(Red.Promoter == "PCH5") %>% group_by(Plant, Date) %>%
  summarize(Plant_CV = sd(Green.Red)/mean(Green.Red))

plot_lognormal_distribution_with_fit(PCH5$Plant_CV)
plot_lognormal_distribution_with_probabilities(PCH5$Plant_CV)
#meanlog = -1.695
#sdlog = 0.302
PCH5_effect_10 = compare_2_custom(1.2, pops_meanlog = -1.695, pops_sdlog = 0.302)
PCH5_effect_10$t_tests_correct = PCH5_effect_10$t_tests_correct - 9
PCH5_effect_10$total_plant_number = as.factor(PCH5_effect_10$total_plant_number)
PCH5_effect20_summary = PCH5_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCH5")

#PCL1
PCL1 = weekly_norm %>% filter(Red.Promoter == "PCL1") %>% group_by(Plant, Date) %>%
  summarize(Plant_CV = sd(Green.Red)/mean(Green.Red))

plot_lognormal_distribution_with_fit(PCL1$Plant_CV)
plot_lognormal_distribution_with_probabilities(PCL1$Plant_CV)
#meanlog = -1.713
#sdlog = 0.448
PCL1_effect_10 = compare_2_custom(1.2, pops_meanlog = -1.713, pops_sdlog = 0.448)
PCL1_effect_10$t_tests_correct = PCL1_effect_10$t_tests_correct - 9
PCL1_effect_10$total_plant_number = as.factor(PCL1_effect_10$total_plant_number)
PCL1_effect20_summary = PCL1_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCL1")

#PCL2
PCL2 = weekly_norm %>% filter(Red.Promoter == "PCL2") %>% group_by(Plant, Date) %>%
  summarize(Plant_CV = sd(Green.Red)/mean(Green.Red))

plot_lognormal_distribution_with_fit(PCL2$Plant_CV)
plot_lognormal_distribution_with_probabilities(PCL2$Plant_CV)
#meanlog = -2.585
#sdlog = 0.357
PCL2_effect_10 = compare_2_custom(1.2, pops_meanlog = -2.585, pops_sdlog = 0.357)
PCL2_effect_10$t_tests_correct = PCL2_effect_10$t_tests_correct - 9
PCL2_effect_10$total_plant_number = as.factor(PCL2_effect_10$total_plant_number)
PCL2_effect20_summary = PCL2_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCL2")


#PCM1
PCM1 = weekly_norm %>% filter(Red.Promoter == "PCM1") %>% group_by(Plant, Date) %>%
  summarize(Plant_CV = sd(Green.Red)/mean(Green.Red))

plot_lognormal_distribution_with_fit(PCM1$Plant_CV)
plot_lognormal_distribution_with_probabilities(PCM1$Plant_CV)
#meanlog = -2.131
#sdlog = 0.303
PCM1_effect_10 = compare_2_custom(1.2, pops_meanlog = -2.131, pops_sdlog = 0.303)
PCM1_effect_10$t_tests_correct = PCM1_effect_10$t_tests_correct - 9
PCM1_effect_10$total_plant_number = as.factor(PCM1_effect_10$total_plant_number)
PCM1_effect20_summary = PCM1_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCM1")


#PCM2
PCM2 = weekly_norm %>% filter(Red.Promoter == "PCM2") %>% group_by(Plant, Date) %>%
  summarize(Plant_CV = sd(Green.Red)/mean(Green.Red))

plot_lognormal_distribution_with_fit(PCM2$Plant_CV)
plot_lognormal_distribution_with_probabilities(PCM2$Plant_CV)
#meanlog = -1.725
#sdlog = 0.305
PCM2_effect_10 = compare_2_custom(1.2, pops_meanlog = -1.725, pops_sdlog = 0.305)
PCM2_effect_10$t_tests_correct = PCM2_effect_10$t_tests_correct - 9
PCM2_effect_10$total_plant_number = as.factor(PCM2_effect_10$total_plant_number)
PCM2_effect20_summary = PCM2_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCM2")

#GFP alone
GFP_alone = weekly_norm %>% filter(is.na(Red.Promoter)) %>% group_by(Plant, Date) %>%
  summarize(Plant_CV = sd(Green)/mean(Green))

plot_lognormal_distribution_with_fit(GFP_alone$Plant_CV)
plot_lognormal_distribution_with_probabilities(GFP_alone$Plant_CV)
#meanlog = -1.826
#sdlog = 0.343

GFP_effect_10 = compare_2_custom(1.2, pops_meanlog = -1.826, pops_sdlog = 0.343)
GFP_effect_10$t_tests_correct = GFP_effect_10$t_tests_correct - 9
GFP_effect_10$total_plant_number = as.factor(GFP_effect_10$total_plant_number)
GFP_effect20_summary = GFP_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "GFP")



#PCH4: 0.165
#PCH5: 0.192
#PCL1: 0.198
#PCL2: 0.081
#PCM1: 0.125
#PCM2: 0.186
#GFP alone: 0.170
effect_20_summary = rbind(PCH4_effect20_summary, PCH5_effect20_summary)
effect_20_summary = rbind(effect_20_summary, PCL1_effect20_summary)
effect_20_summary = rbind(effect_20_summary, PCL2_effect20_summary)
effect_20_summary = rbind(effect_20_summary, PCM1_effect20_summary)
effect_20_summary = rbind(effect_20_summary, PCM2_effect20_summary)
effect_20_summary = rbind(effect_20_summary, GFP_effect20_summary)


promoter_20$Promoter = factor(promoter_20$Promoter, levels = c("GFP_control", "PCL2", "PCM1", "PCM2", "PCH4", "PCH5", "PCL1"))
promoter_20 %>% ggplot(aes(x = Promoter, y = total_plant_number, fill = Normalized)) + geom_col() +
  theme_light() +
  labs(title = "Required plants for 20% effect size detection") +
  theme(
    axis.text.x = element_text(face = "bold", color = "black", size = 10),
    axis.text.y = element_text(face = "bold", color = "black", size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2)
  ) +
  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +  # Set y-axis limits from 0 to 10
  xlab("Normalizer promoter") +
  ylab("Plants required")



######

#30 percent effect size with 20 plants
PCH5_effect_10 = compare_2_custom(1.3, pops_meanlog = -1.695, pops_sdlog = 0.302)
PCH5_effect_10$t_tests_correct = PCH5_effect_10$t_tests_correct - 9
PCH5_effect_10$total_plant_number = as.factor(PCH5_effect_10$total_plant_number)
PCH5_effect10_summary = PCH5_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCH5")

PCH4_effect_10 = compare_2_custom(1.3, pops_meanlog = -1.865, pops_sdlog = 0.354)
PCH4_effect_10$t_tests_correct = PCH4_effect_10$t_tests_correct - 9
PCH4_effect_10$total_plant_number = as.factor(PCH4_effect_10$total_plant_number)
PCH4_effect10_summary = PCH4_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100 * (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCH4")

PCL1_effect_10 = compare_2_custom(1.3, pops_meanlog = -1.713, pops_sdlog = 0.448)
PCL1_effect_10$t_tests_correct = PCL1_effect_10$t_tests_correct - 9
PCL1_effect_10$total_plant_number = as.factor(PCL1_effect_10$total_plant_number)
PCL1_effect10_summary = PCL1_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCL1")

PCL2_effect_10 = compare_2_custom(1.3, pops_meanlog = -2.585, pops_sdlog = 0.357)
PCL2_effect_10$t_tests_correct = PCL2_effect_10$t_tests_correct - 9
PCL2_effect_10$total_plant_number = as.factor(PCL2_effect_10$total_plant_number)
PCL2_effect10_summary = PCL2_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCL2")

PCM1_effect_10 = compare_2_custom(1.3, pops_meanlog = -2.131, pops_sdlog = 0.303)
PCM1_effect_10$t_tests_correct = PCM1_effect_10$t_tests_correct - 9
PCM1_effect_10$total_plant_number = as.factor(PCM1_effect_10$total_plant_number)
PCM1_effect10_summary = PCM1_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCM1")


PCM2_effect_10 = compare_2_custom(1.3, pops_meanlog = -1.725, pops_sdlog = 0.305)
PCM2_effect_10$t_tests_correct = PCM2_effect_10$t_tests_correct - 9
PCM2_effect_10$total_plant_number = as.factor(PCM2_effect_10$total_plant_number)
PCM2_effect10_summary = PCM2_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "PCM2")

GFP_effect_10 = compare_2_custom(1.3, pops_meanlog = -1.826, pops_sdlog = 0.343)
GFP_effect_10$t_tests_correct = GFP_effect_10$t_tests_correct - 9
GFP_effect_10$total_plant_number = as.factor(GFP_effect_10$total_plant_number)
GFP_effect10_summary = GFP_effect_10 %>% group_by(total_plant_number) %>% 
  summarize(percent_correct = 100* (sum(t_tests_correct)/1000)) %>%
  filter(percent_correct >= 95) %>% 
  reframe(min = min(percent_correct), total_plant_number) %>% slice(1) %>% mutate(Promoter = "GFP")

effect_30_summary = rbind(PCH4_effect10_summary, PCH5_effect10_summary)
effect_30_summary = rbind(effect_30_summary, PCL1_effect10_summary)
effect_30_summary = rbind(effect_30_summary, PCL2_effect10_summary)
effect_30_summary = rbind(effect_30_summary, PCM1_effect10_summary)
effect_30_summary = rbind(effect_30_summary, PCM2_effect10_summary)
effect_30_summary = rbind(effect_30_summary, GFP_effect10_summary)

```
#allows for weekly meanlog and sdlog to be user specified
```{r}
generate_weekly_CV_average_custom = function(pops_meanlog, pops_sdlog){
  weekly_CV_meanlog = pops_meanlog  #meanlog of weekly CVs
  weekly_CV_sdlog = pops_sdlog    # sdlog of weekly CVs

  y = runif(1, min = 0, max = 1)

  # Compute the corresponding x value
  weeks_CV <- qlnorm(y, meanlog = weekly_CV_meanlog, sdlog = weekly_CV_sdlog)
  
  ####################################################################
  #adds stochastic standard deviation of CV based on our data 
  CV_sd_meanlog = -2.3248 #meanlog of weekly sd's of CV values
  CV_sd_sdlog = 0.3897 #sd log of weekly sd's of CV values

  magnitiude_sd_of_CV <- runif(1, min = 0, max = 1)  

  # Compute the corresponding x value
  sd_of_CV <- qlnorm(magnitiude_sd_of_CV, meanlog = CV_sd_meanlog, sdlog = CV_sd_sdlog)
  
  
  # Compute sdlog
  sdlog <- sqrt(log(1 + (sd_of_CV^2 / weeks_CV^2)))
  
  generated_weekly_CV = data.frame(log_CV = log(weeks_CV), log_sd = sdlog)
  
  
  
  return(generated_weekly_CV)
}
```

#compare to constructs of a specified effect size with user-specified plant population 
#meanlog and sdlog values
```{r}
compare_2_custom = function(effect_size, pops_meanlog, pops_sdlog){
  
low_value = 100000
effect_size_to_add = (100000 * effect_size) - 100000
true_values <- data.frame(
  construct = c(1,2),
  value = c(low_value,
            low_value + effect_size_to_add))

percent_valid_tests = data.frame(plant_number = NULL, percent_valid = NULL)
number_tests = 1000
conglomerate_tests = data.frame(plant_number = NULL, GFP = NULL, construct = NULL,
                                rep = NULL, total_plants = NULL)
conglomerate_tests_collect = FALSE

experimental_summary = data.frame(ranked_properly = NULL, t_test_percent = NULL, plant_number = NULL, rep = NULL)

#defines total number of plants that will be tested
for(plant_number in 33:40){
  number_plants_to_generate = plant_number
  number_successful_comparisons = 0
  
  print(number_plants_to_generate)
  
  #number simulations
  for(iterations in 1:number_tests){
    GFP_distribution = data.frame(plant_number = NULL, GFP = NULL, construct = NULL)
    weekly_CV = generate_weekly_CV_average_custom(pops_meanlog = pops_meanlog, pops_sdlog = pops_sdlog )
    
    #defined number of constructs
    for(construct in 1:length(true_values$construct)){
      
      #defines number of plants for this iteration
      for(plants in 1:number_plants_to_generate){
        plant_CV = generate_plant_CV(weekly_CV) #generate plant
        plant_number = as.factor(plants)
        
        GFP_output = generate_8_disks(true_values$value[construct], plant_CV, plant_number)
        GFP_output = GFP_output %>% mutate(construct = true_values$construct[construct])
        
        GFP_distribution = rbind(GFP_distribution, GFP_output)
      }
      
      if(conglomerate_tests_collect == TRUE){
        experiment_data = GFP_distribution %>% 
          mutate(rep = as.factor(iterations), total_plants = as.factor(number_plants_to_generate))
        conglomerate_tests = rbind(conglomerate_tests, experiment_data)
      }
    }
    
    #determine if experiment can successfully differentiate all samples
    iteration_results = calculate_ranking_significance(GFP_distribution)
    iteration_results = iteration_results %>% mutate(total_plant_number = number_plants_to_generate,
                                                     rep = as.factor(iterations))
    
    
    if(iterations %% 100 == 0){
      print(paste(c(iterations, "iterations of plant number ", number_plants_to_generate, " completed")))
    }
    
    experimental_summary = rbind(experimental_summary, iteration_results)
  }
  
  
}
experimental_summary = experimental_summary %>% mutate(effect_size = effect_size)
return(experimental_summary)
}
```

```{r}

EHA105_15 = compare_2_custom(1.15, pops_meanlog = -0.903, pops_sdlog = 0.46 )
EHA105_30 = compare_2_custom(1.3, pops_meanlog = -0.903, pops_sdlog = 0.46 )
EHA105_50 = compare_2_custom(1.50, pops_meanlog = -0.903, pops_sdlog = 0.46 )
EHA105_70 = compare_2_custom(1.70, pops_meanlog = -0.903, pops_sdlog = 0.46 )
EHA105_100 = compare_2_custom(2, pops_meanlog = -0.903, pops_sdlog = 0.46 )
EHA105_200 = compare_2_custom(3, pops_meanlog = -0.903, pops_sdlog = 0.46 )
EHA105_200_2 = compare_2_custom(1.15, pops_meanlog = -0.903, pops_sdlog = 0.46 )
EHA105_200_2$t_tests_correct = EHA105_200_2$t_tests_correct - 9
EHA105_200_2 %>% group_by(as.factor(total_plant_number)) %>%
  summarize(total = 100 * sum(t_tests_correct) / n())

combined_EHA105 = rbind(EHA105_15, EHA105_30)
combined_EHA105 = rbind(combined_EHA105, EHA105_50)
combined_EHA105 = rbind(combined_EHA105, EHA105_70)
combined_EHA105 = rbind(combined_EHA105, EHA105_100)
combined_EHA105 = rbind(combined_EHA105, EHA105_200)

combined_EHA105$Strain = "EHA105"
combined_EHA105$effect_size = as.factor(combined_EHA105$effect_size)
combined_EHA105$total_plant_number = as.factor(combined_EHA105$total_plant_number)
combined_EHA105$t_tests_correct = combined_EHA105$t_tests_correct - 9

combined_EHA105 %>% group_by(effect_size, total_plant_number) %>%
  summarize(percent_correct = 100*(sum(t_tests_correct)/n())) %>% ungroup() %>%
  filter(percent_correct > 95) %>%
  group_by(effect_size) %>%
  summarize(min_plants_needed = min(as.integer(total_plant_number) + 1))

pCL2_15 = compare_2_custom(1.15, pops_meanlog = -2.585, pops_sdlog = 0.357 )
pCL2_30 = compare_2_custom(1.3, pops_meanlog = -2.585, pops_sdlog = 0.357 )
pCL2_50 = compare_2_custom(1.5, pops_meanlog = -2.585, pops_sdlog = 0.357 )
pCL2_70 = compare_2_custom(1.7, pops_meanlog = -2.585, pops_sdlog = 0.357 )
pCL2_100 = compare_2_custom(2, pops_meanlog = -2.585, pops_sdlog = 0.357 )
pCL2_200 = compare_2_custom(3, pops_meanlog = -2.585, pops_sdlog = 0.357 )
pCL2_200_2 = compare_2_custom(2, pops_meanlog = -2.585, pops_sdlog = 0.357 )
pCL2_200_2$t_tests_correct = pCL2_200_2$t_tests_correct - 9
pCL2_200_2 %>% summarize(total = 100 * sum(t_tests_correct) / n())


combined_pCL2 = rbind(pCL2_15, pCL2_30)
combined_pCL2 = rbind(combined_pCL2, pCL2_50)
combined_pCL2 = rbind(combined_pCL2, pCL2_70)
combined_pCL2 = rbind(combined_pCL2, pCL2_100)
combined_pCL2 = rbind(combined_pCL2, pCL2_200)


combined_pCL2$Strain = "pCL2"
combined_pCL2$effect_size = as.factor(combined_pCL2$effect_size)
combined_pCL2$total_plant_number = as.factor(combined_pCL2$total_plant_number)
combined_pCL2$t_tests_correct = combined_pCL2$t_tests_correct - 9

pCL2_final = combined_pCL2 %>% group_by(effect_size, total_plant_number) %>%
  summarize(percent_correct = 100*(sum(t_tests_correct)/n())) %>% ungroup() %>%
  filter(percent_correct > 95) %>%
  group_by(effect_size) %>%
  summarize(min_plants_needed = min(as.integer(total_plant_number) + 1))

GV3101_15 = compare_2_custom(1.15, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_30 = compare_2_custom(1.3, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_50 = compare_2_custom(1.5, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_70 = compare_2_custom(1.7, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_100 = compare_2_custom(2, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_200 = compare_2_custom(3, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_200_2 = compare_2_custom(1.15, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_200_2$t_tests_correct = GV3101_200_2$t_tests_correct - 9
GV3101_200_2 %>% group_by(as.factor(total_plant_number)) %>% 
  summarize(total = 100 * sum(t_tests_correct) / n())

combined_GV3101 = rbind(GV3101_15, GV3101_30)
combined_GV3101 = rbind(combined_GV3101, GV3101_50)
combined_GV3101 = rbind(combined_GV3101, GV3101_70)
combined_GV3101 = rbind(combined_GV3101, GV3101_100)
combined_GV3101 = rbind(combined_GV3101, GV3101_200)

combined_GV3101$Strain = "GV3101"
combined_GV3101$effect_size = as.factor(combined_GV3101$effect_size)
combined_GV3101$total_plant_number = as.factor(combined_GV3101$total_plant_number)
combined_GV3101$t_tests_correct = combined_GV3101$t_tests_correct - 9
combined_GV3101$plant_num = as.numeric(combined_GV3101$total_plant_number) + 1

combined_GV3101 %>% group_by(effect_size, total_plant_number) %>%
  summarize(percent_correct = 100*(sum(t_tests_correct)/n())) %>% ungroup() %>%
  filter(percent_correct > 95) %>%
  group_by(effect_size) %>%
  summarize(min_plants_needed = min(as.integer(total_plant_number) + 1))




all_combined = rbind(combined_GV3101, combined_pCL2)
all_combined = rbind(all_combined, combined_EHA105)
all_combined$t_tests_correct = all_combined$t_tests_correct - 9

```

```{r}
#weekly_CV_meanlog = -1.447  #meanlog of weekly CVs
  #weekly_CV_sdlog = 0.3    # sdlog of weekly CVs
GV3101_100_plants = compare_2_custom(1.05, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_100_plants$t_tests_correct = GV3101_100_plants$t_tests_correct - 9
GV3101_100_plants %>% summarize(correct = sum(t_tests_correct), total = n())
#5% = 89.6%

GV3101_100_plants_1.07 = compare_2_custom(1.07, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_100_plants_1.07$t_tests_correct = GV3101_100_plants_1.07$t_tests_correct - 9
GV3101_100_plants_1.07 %>% summarize(correct = sum(t_tests_correct), total = n())
#98.2

GV3101_100_plants_1.06 = compare_2_custom(1.06, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_100_plants_1.06$t_tests_correct = GV3101_100_plants_1.06$t_tests_correct - 9
GV3101_100_plants_1.06 %>% summarize(correct = sum(t_tests_correct), total = n())
#96.0%

GV3101_100_plants_1.057 = compare_2_custom(1.057, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_100_plants_1.057$t_tests_correct = GV3101_100_plants_1.057$t_tests_correct - 9
GV3101_100_plants_1.057 %>% summarize(correct = sum(t_tests_correct), total = n())
#96.0%

#EHA105
#weekly_CV_meanlog = -0.903  #meanlog of weekly CVs
  #weekly_CV_sdlog = 0.46    # sdlog of weekly CVs

EHA105_100_plants_1.1 = compare_2_custom(1.1, pops_meanlog = -0.903, pops_sdlog = 0.46)
EHA105_100_plants_1.1$t_tests_correct = EHA105_100_plants_1.1$t_tests_correct - 9
EHA105_100_plants_1.1 %>% summarize(correct = sum(t_tests_correct), total = n())
#97.2

EHA105_50_plants_1.1 = compare_2_custom(1.1, pops_meanlog = -0.903, pops_sdlog = 0.46)
EHA105_50_plants_1.1$t_tests_correct = EHA105_50_plants_1.1$t_tests_correct - 9
EHA105_50_plants_1.1 %>% summarize(correct = sum(t_tests_correct), total = n())
#86.3

GV3101_50_plants_1.06 = compare_2_custom(1.06, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_50_plants_1.06$t_tests_correct = GV3101_50_plants_1.06$t_tests_correct - 9
GV3101_50_plants_1.06 %>% summarize(correct = sum(t_tests_correct), total = n())

GV3101_50_plants_1.1 = compare_2_custom(1.1, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_50_plants_1.1$t_tests_correct = GV3101_50_plants_1.1$t_tests_correct - 9
GV3101_50_plants_1.1 %>% summarize(correct = sum(t_tests_correct), total = n())

GV3101_50_plants_1.12 = compare_2_custom(1.12, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_50_plants_1.12$t_tests_correct = GV3101_50_plants_1.12$t_tests_correct - 9
GV3101_50_plants_1.12 %>% summarize(correct = sum(t_tests_correct), total = n())

GV3101_50_plants_1.15 = compare_2_custom(1.15, pops_meanlog = -1.447, pops_sdlog = 0.3)
GV3101_50_plants_1.15$t_tests_correct = GV3101_50_plants_1.15$t_tests_correct - 9
GV3101_50_plants_1.15 %>% summarize(correct = sum(t_tests_correct), total = n())

GV3101_50_plants_1.1 = find_optimal_input(starting_guess = 1.1) #GV3101 with 50 plants: 1.0875, 95.5%
EHA105_50_plants_1.1 = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) #EHA105 50 plants: 1.125

#PCL2_effect_10 = compare_2_custom(1.3, pops_meanlog = -2.585, pops_sdlog = 0.357)
PCL2_50_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) #pCL2 50 plants: 1.0688

##25 plants
GV3101_25_plants = find_optimal_input(starting_guess = 1.1) #GV3101 25 plants: 1.125
EHA105_25_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) #EHA105 25 plants: 1.1875
PCL2_25_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) #pCL2 25 plants: 1.1031

#10 plants
GV3101_10_plants = find_optimal_input(starting_guess = 1.1) 
EHA105_10_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) 
PCL2_10_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) 

#5 plants
GV3101_5_plants = find_optimal_input(starting_guess = 1.1) 
EHA105_5_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) 
PCL2_5_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) 

#3 plants
GV3101_3_plants = find_optimal_input(starting_guess = 1.1) 
EHA105_3_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) 
PCL2_3_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) 

#2 plants
GV3101_2_plants = find_optimal_input(starting_guess = 1.1) 
EHA105_2_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) 
PCL2_2_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) 

#21 plant
GV3101_1_plants = find_optimal_input(starting_guess = 1.1) 
EHA105_1_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) 
PCL2_1_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) 

#4 plant
GV3101_4_plants = find_optimal_input(starting_guess = 1.1) 
EHA105_4_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) 
PCL2_4_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) 


GV3101_16_plants = find_optimal_input(starting_guess = 1.1) 
EHA105_16_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) 
PCL2_16_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) 


GV3101_37_plants = find_optimal_input(starting_guess = 1.1) 
EHA105_37_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) 
PCL2_37_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) 

GV3101_7_plants = find_optimal_input(starting_guess = 1.1) 
EHA105_7_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) 
PCL2_7_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) 

GV3101_6_plants = find_optimal_input(starting_guess = 1.1) 
EHA105_6_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -0.903, pops_sdlog = 0.46) 
PCL2_6_plants = find_optimal_input(starting_guess = 1.1, pops_meanlog = -2.585, pops_sdlog = 0.357) 

```

```{r}
library(tibble)

effect_size_modeling <- tibble(
  Strain = c(
    rep("EHA105", 12),
    rep("GV3101", 12),
    rep("pCL2", 12)
  ),
  Plants = c(
    50,25,10,5,3,2,1,4,16,37,7,6,
    50,25,10,5,3,2,1,4,16,37,7,6,
    50,25,10,5,3,2,1,4,16,37,7,6
  ),
  Min_effect_size = c(
    1.125,1.1875,1.3,1.5063,1.7016,1.975,2.975,1.5375,1.2375,1.15,1.3875,1.4,
    1.0875,1.125,1.1875,1.2875,1.4125,1.5375,1.975,1.35,1.1562,1.1,1.25,1.2686,
    1.0688,1.1031,1.1625,1.2328,1.3188,1.4281,1.725,1.2563,1.125,1.0813,1.1938,1.2
  ),
  Effect_size = c(
    12.5,18.75,30,50.63,70.16,97.5,197.5,53.75,23.75,15,38.75,40,
    8.75,12.5,18.75,28.75,41.25,53.75,97.5,35,15.62,10,25,26.86,
    6.88,10.31,16.25,23.28,31.88,42.81,72.5,25.63,12.5,8.13,19.38,20
  )
)

#GV3101
GV3101 = effect_size_modeling %>% filter(Strain == "pCL2") %>% filter(Plants < 30 & Plants >2)

# Fit model: y = a * exp(-b / x)
model <- nls(Plants ~ a * exp(-b / Effect_size), data = GV3101, start = list(a = 1, b = 1))

# Summary of model fit
summary(model)

# Predict and plot
GV3101$pred <- predict(model) 

#GV3101: a = 1.6615, b = -34.1236
#EHA105: a = 1.9115, b = -48.6043
#pCL2: a = 1.4886, b = -29.2417

library(ggplot2)
ggplot(GV3101, aes(x = Effect_size, y = Plants)) +
  geom_point() +
  geom_line(aes(y = pred), color = "blue")


effect_size_modeling %>% filter(Plants > 1 & Plants < 30) %>% ggplot(aes(x = Effect_size, y = Plants, color = Strain)) +
  geom_point() +
  geom_smooth(method = "nls", se = FALSE,
              formula = Plants ~ a * exp(-b / Effect_size),
              method.args = list(start = list(a = 1, b = 1)))


# Define a sequence of x-values
x_vals <- seq(6.5, 21, length.out = 300)

# Define parameters for 3 functions
params <- tribble(
  ~Strain, ~a, ~b,
  "GV3101", 1.6615, -34.1236,
  "EHA105", 1.9115, -48.6043,
  "pCL2", 1.4886, -29.2417
)

# Generate y-values for each function
plot_data <- params %>%
  rowwise() %>%
  mutate(data = list(tibble(
    x = x_vals,
    y = a * exp(-b / x)
  ))) %>%
  unnest(data)

# Plot
ggplot(plot_data, aes(x = x, y = log2(y), color = Strain)) +
  geom_line(size = 1)  + geom_hline(yintercept = log2(50), linetype = "dashed", color = "black") +
  geom_vline(xintercept = 10.02) + geom_vline(xintercept = 14.89) + geom_vline(xintercept = 8.32) +
  labs(x = "Effect_size", y = "Predicted Plants")

compute_x_given_y <- function(a, b, y_target = 50) {
  -b / log(y_target / a)
}

params <- tibble(
  Strain = c("GV3101", "EHA105", "pCL2"),
  a = c(1.6615, 1.9115, 1.4886),
  b = c(-34.1236, -48.6043, -29.2417)
)

params <- params %>%
  mutate(x_at_y50 = compute_x_given_y(a, b, y_target = 100))

print(params)
#50 plant cutoffs:
#GV3101: 10.02
#EHA105: 14.89
#pCL2: 8.32


params <- tibble(
  Strain = c("GV3101", "EHA105", "pCL2"),
  a = c(1.6615, 1.9115, 1.4886),
  b = c(-34.1236, -48.6043, -29.2417)
) %>%
  mutate(
    x_at_y50 = -b / log(20 / a),
    y_at_50 = log2(20)
  )


# Step 2: Add to plot
ggplot(plot_data, aes(x = x, y = log2(y), color = Strain)) +
  geom_line(size = 1) +  geom_hline(yintercept = log2(20), linetype = "dotted", color = "black") +
  geom_point(data = params, aes(x = x_at_y50, y = y_at_50, color = Strain), size = 3) +
  #geom_point(data = params, aes(x = x_at_y50, y = -Inf, color = Strain), size = 3) +
  geom_segment(
  data = params,
  aes(x = x_at_y50, xend = x_at_y50, y = -Inf, yend = y_at_50, color = Strain),
  linetype = "dashed",
  size = 1.2  # increase thickness
) +
  labs(x = "Effect_size", y = "Predicted Plants") +
 ylim(c(2.5, 11)) + xlim(c(6.5, 21)) +
  theme_light() +
  theme(
    #axis.text.x = element_blank(),
    #axis.text.y = element_blank(),
    #axis.ticks = element_blank(),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.border = element_rect(color = "black", size = 2),
    #legend.position = "none"
  ) + ylab("Log2 Plants Required") + xlab("Percent Effect Size") +
  ggtitle("Effect size vs minimum required plants")
```

```{r}
find_optimal_input <- function(starting_guess = 1.1,
                               pops_meanlog = -1.447,
                               pops_sdlog = 0.3,
                               target_min = 945,
                               target_max = 955,
                               tolerance = 0.01,
                               verbose = TRUE) {
  low <- NA
  high <- NA
  guess <- starting_guess

  repeat {
    # Run simulation and adjust
    result <- compare_2_custom(guess, pops_meanlog = pops_meanlog, pops_sdlog = pops_sdlog)
    result$t_tests_correct <- result$t_tests_correct - 9
    correct_total <- sum(result$t_tests_correct)

    if (verbose) {
      cat("Guess:", round(guess, 4), "- Correct:", correct_total, "\n")
    }

    # Check if in desired range
    if (correct_total >= target_min && correct_total <= target_max) {
      break
    }

    # Update bounds
    if (correct_total < target_min) {
      low <- guess
    } else {
      high <- guess
    }

    # Compute new guess
    if (!is.na(low) && !is.na(high)) {
      guess <- (low + high) / 2
    } else if (!is.na(low)) {
      guess <- low + 0.2
    } else if (!is.na(high)) {
      guess <- high - 0.1
    }

    # Stop if interval is too narrow
    if (!is.na(low) && !is.na(high) && (high - low) < tolerance) {
      break
    }
  }

  if (verbose) {
    cat("Final guess within target range:", round(guess, 4), "\n")
  }

  return(guess)
}
```

#Mixed effect modeling
```{r}
#Using only data from the pCM2::GFP dataset 

#pCM2_data = read.csv(...pCM2_data.csv)
# --- Final model: random intercepts & slopes by Date and by Plant ---
m_final <- lmer(
  log_GFP ~ Leaf_c +
    (1 + Leaf_c | Date) +                 # week-specific mean and TopBottom
    (1 + Leaf_c | Unique_plant_ID),       # plant mean + plant TopBottom heterogeneity
  data = pCM2_data, REML = TRUE
)

#Variance analysis for each component
var_percent_table_exact <- function(fit, log_base = 10, digits = 1) {
  vc <- as.data.frame(VarCorr(fit)) %>%
    filter(is.na(var2) | var1 == var2) %>%
    transmute(
      grp, var1, variance = vcov,
      component = dplyr::case_when(
        grp == "Residual" ~ "Residual",
        grp == "Date" & var1 == "(Intercept)" ~ "Date_mean",
        grp == "Date" ~ "Date_TopBottom",
        grp == "Unique_plant_ID" & var1 == "(Intercept)" ~ "Plant_mean",
        grp == "Unique_plant_ID" ~ "Plant_TopBottom",
        TRUE ~ paste(grp, var1, sep=":")
      ),
      sd = sqrt(variance),
      mult_factor = if (log_base==10) 10^sd else exp(sd)
    ) %>%
    select(component, variance, sd, mult_factor)}

#Multiplicative scatter for main model
tbl_final <- var_percent_table_exact(m_final, log_base = 10)



#Analysis of leaf position and technical variance
m_leafc <- lmer(
  log_GFP ~ Position + Leaf_c +
    (1 + Leaf_c | Plant) +
    (1 | Plant:Leaf:Site) +
    (1 | DiskID) +
    (1 | DiskID:Position),
  data = df, REML = TRUE
)

# (C) Extract diagonal variances and label ------------------------------------
vc_df <- as.data.frame(VarCorr(m_leafc))

# Keep only diagonal (variance) rows + residual
vc_diag <- vc_df %>%
  filter(is.na(var2)) %>%                 # variances only
  transmute(
    grp  = grp,
    term = ifelse(is.na(var1), "Residual", var1),
    var  = vcov
  )

get_var <- function(g, t) {
  v <- vc_diag %>% filter(grp == g, term == t) %>% pull(var)
  if (length(v) == 0) 0 else v
}

plant_slope <- vc_diag %>%
  filter(grp == "Plant", grepl("^Leaf", term)) %>%
  summarise(v = sum(var, na.rm = TRUE), .groups = "drop") %>%
  pull(v)
if (length(plant_slope) == 0) plant_slope <- 0

# Build labeled table
final <- tribble(
  ~component,                                      ~var,
  "Plant topbottom heterogeneity (Leaf_c slope)",  plant_slope,
  "Plant mean (intercept)",                         get_var("Plant", "(Intercept)"),
  "Leaf-site (distal vs proximal) within leaf",     get_var("Plant:Leaf:Site", "(Intercept)"),
  "Disk (punch) within site",                       get_var("DiskID", "(Intercept)"),
  "Positional (flip within disk)",                  get_var("DiskID:Position", "(Intercept)"),
  "Technical (repeat scan)",                        get_var("Residual", "Residual")
) %>%
  mutate(prop_total = var / sum(var)) %>%
  arrange(desc(prop_total))

```
#Ruby analysis
```{r}
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
library(lme4)
library(broom.mixed)
library(tibble)
library(stringr)
# ---------------------------------------------------------------------------
# Input: ruby_data 
# Columns required:
#   Well, abs, Experimental_replicate, Plant, Leaf, Condition,
#   Dry_weight_mg, abs_per_mg
# ---------------------------------------------------------------------------
#ruby_data = read.csv("/.../ruby_data.csv")
ruby_data_processed <- ruby_data %>%
  mutate(
    Condition             = factor(Condition),
    Experimental_replicate = factor(Experimental_replicate),
    Plant                 = factor(Plant),
    Leaf                  = factor(Leaf),
    Leaf_c                = if_else(Leaf == "T4", -0.5, 0.5),
    ln_abs_per_mg         = log(abs_per_mg)   # analysis scale
  ) %>%
  droplevels()

# Conditions of interest
conds_of_interest <- c("T2A", "co-infiltration")
ruby_filt <- ruby_data2 %>%
  filter(Condition %in% conds_of_interest) %>%
  droplevels()

`%||%` <- function(x, y) if (is.null(x) || length(x) == 0) y else x

# ---------------------------------------------------------------------------
# Helper: pooled (all weeks) model  SDs (ln scale)
# ---------------------------------------------------------------------------
fit_pooled_and_refs <- function(dat) {
  fit <- lmer(
    ln_abs_per_mg ~ Leaf_c +
      (1 | Experimental_replicate) +
      (1 | Experimental_replicate:Plant),
    data = dat, REML = TRUE
  )

  vc <- as.data.frame(VarCorr(fit))

  ref_tbl <- vc %>%
    transmute(
      grp,
      sd_ref = sqrt(vcov),   # SD on ln scale
      component = case_when(
        grp == "Experimental_replicate:Plant" ~ "Plant mean within Week",
        grp == "Residual"                     ~ "Residual",
        grp == "Experimental_replicate"       ~ "Week baseline",
        TRUE                                  ~ grp
      )
    ) %>%
    filter(component %in% c("Plant mean within Week", "Residual"))

  list(fit = fit, ref_tbl = ref_tbl)
}

# ---------------------------------------------------------------------------
# Helper: weekly model  SDs (ln scale)
# ---------------------------------------------------------------------------
fit_one_week <- function(week_df) {
  f <- tryCatch(
    lmer(ln_abs_per_mg ~ Leaf_c + (1 | Plant),
         data = week_df, REML = TRUE),
    error = function(e) NULL
  )

  if (is.null(f)) {
    return(tibble(
      Experimental_replicate = unique(week_df$Experimental_replicate),
      component = c("Plant mean within Week", "Residual"),
      sd = NA_real_
    ))
  }

  vc <- as.data.frame(VarCorr(f))

  tibble(
    Experimental_replicate = unique(week_df$Experimental_replicate),
    component = c("Plant mean within Week", "Residual"),
    sd = c(
      sqrt(vc$vcov[vc$grp == "Plant"])    %||% NA_real_,
      sqrt(vc$vcov[vc$grp == "Residual"]) %||% NA_real_
    )
  )
}

# ---------------------------------------------------------------------------
# Build weekly SD table + pooled refs
# ---------------------------------------------------------------------------
by_condition <- ruby_filt %>%
  group_split(Condition) %>%
  set_names(nm = levels(ruby_filt$Condition))

pooled_refs <- map(by_condition, fit_pooled_and_refs)

ref_df <- imap_dfr(
  pooled_refs,
  ~ .x$ref_tbl %>%
    mutate(Condition = .y)
) %>%
  select(Condition, component, sd_ref)

weekly_sd <- imap_dfr(
  by_condition,
  function(df_cond, cond_name) {
    df_cond %>%
      group_split(Experimental_replicate) %>%
      map_dfr(fit_one_week) %>%
      mutate(Condition = cond_name)
  }
)

# ---------------------------------------------------------------------------
# Prepare long results table (ln SD  multiplicative scatter = exp(sd))
# ---------------------------------------------------------------------------
week_long_ruby <- weekly_sd %>%
  mutate(
    Week         = as.character(Experimental_replicate),
    sd_log       = sd,           
    mult_scatter = exp(sd_log)    
  ) %>%
  select(Week, Component = component, Condition, sd_log, mult_scatter) %>%
  arrange(Condition, Week, Component)
```

#PDC analysis
```{r}
#pdc = read.csv("/.../pdc_data.csv")
pdc_scatter <- pdc %>%
  group_by(Week) %>%
  summarise(
    mean_log10 = mean(log10, na.rm = TRUE),
    sd_log10   = sd(log10, na.rm = TRUE),
    mult       = 10^sd_log10,     
    n          = n(),
    .groups = "drop"
  )


ggplot(pdc_scatter, aes(x = factor(Week), y = sd_log10)) +
  geom_point(size = 2.5) +
  geom_line(aes(group = 1), linewidth = 0.4) +
  coord_flip() +
  scale_y_continuous(
    name = "Residual SD (log10 units)",
    sec.axis = sec_axis(~ ., name = "Multiplicative scatter ()",
                        labels = function(x) sprintf("%.2f", 10^x))
  ) +
  geom_text(aes(label = sprintf("%.2f", mult)),
            vjust = -0.6, size = 3) +
  theme_minimal(base_size = 12) +
  labs(
    x = "Week",
    title = "Week-specific residual variance (PDC concentration)",
    subtitle = "SD on log10 scale with multiplicative scatter ()"
  )
```








